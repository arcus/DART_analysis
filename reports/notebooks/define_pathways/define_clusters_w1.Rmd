---
title: "Pathways clustering"
author: "Rose Hartman"
date: '2023-01-17'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load data

Note that there are two important decisions inherent in the data cleaning process for the likert items (rate your [expertise/relevance to your work/your desire to learn] the following data science tasks): 

- "Not Sure" responses are treated as missing
- All missing values (including Not Sure) are imputed with 1, the lowest value on the scale. In other words, when participants skipped an item or marked it "Not Sure" we're treating that as them indicating "Very Low" expertise/relevance/desire to learn. 

Also note that these items are being treated as continuous variables in this analysis (i.e. the increase from "very low" to "low" is assumed to be the same size as the increase from "low" to "medium", and so on). 

```{r data}
# load the cleaned needs assessment data
needs_assessment <- readRDS(here::here("data", "interim", "needs_assessment.rds")) 

# save just the items to be analyzed (the likert items) 
numeric_data <- dplyr::select(needs_assessment, -record_id)

# convert the record_id column to row names
row.names(numeric_data) <- dplyr::pull(needs_assessment, record_id)

# scale the data
numeric_data_scaled <- scale(numeric_data)
```

# Hierarchical Clustering 

```{r }
dist <- dist(numeric_data_scaled, method = "euclidean")

```

## Finding the clustering method

### Complete
Computes pairwise similarities, and the "most" (i.e., maximum) similar ones are grouped together

```{r complete}
# Hierarchical Clustering with hclust
hc_complete <- hclust(dist, method = "complete")
# Plot the result
plot(hc_complete, cex = 0.6, hang = -1)
```

### Ward's

Minimizes the total **within cluster** variance.

From the docs:

> Two different algorithms are found in the literature for Ward clustering. The one used by option "ward.D" (equivalent to the only Ward option "ward" in R versions <= 3.0.3) does not implement Ward's (1963) clustering criterion, whereas option "ward.D2" implements that criterion (Murtagh and Legendre 2014). With the latter, the dissimilarities are squared before cluster updating. Note that agnes(*, method="ward") corresponds to hclust(*, "ward.D2").

```{r ward}
hc_ward <- hclust(dist, method = "ward.D2")
# Plot the result
plot(hc_ward, cex = 0.6, hang = -1)
```

### Comparing dendograms

Calculate agglomerative coefficient (closer to 1 mean stronger clustering structure)

```{r}
m <- c("average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
purrr::map_dbl(m, ~ cluster::agnes(numeric_data_scaled, method = .)$ac) |>
  round(2)
```

Ward's gives the best cluster cohesion.

```{r save_tree}
# save a copy of the whole tree
saveRDS(hc_ward, file = here::here("data", "interim", "hclust_tree.rds"))
```

## Assigning clusters

```{r cut_tree}
sub_grp4 <- cutree(hc_ward, k = 4)
sub_grp5 <- cutree(hc_ward, k = 5)
sub_grp6 <- cutree(hc_ward, k = 6)
sub_grp7 <- cutree(hc_ward, k = 7)
sub_grp8 <- cutree(hc_ward, k = 8)
sub_grp9 <- cutree(hc_ward, k = 9)
```


```{r save_assignments}
groups <- data.frame(record_id = as.numeric(names(sub_grp4)),
                     group4 = as.factor(sub_grp4), 
                     group5 = as.factor(sub_grp5),
                     group6 = as.factor(sub_grp6),
                     group7 = as.factor(sub_grp7),
                     group8 = as.factor(sub_grp8),
                     group9 = as.factor(sub_grp9))

# join cluster assignments to needs assessment data and save the file
dplyr::left_join(needs_assessment, groups, by = "record_id") |> 
  saveRDS(file = here::here("data", "interim", "needs_assessment_with_clusters.rds"))
```

